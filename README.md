# Privacy-Preserving Machine Learning: A Study on Machine Unlearning and Membership Inference Attacks

This repository contains the code and reports for our project on privacy-preserving machine learning, completed during the Spring 1402-03 semester at Sharif University of Technology. The project is divided into two phases:

## Project Overview

### Phase 0: Theoretical Foundations
This phase focuses on the theoretical aspects of privacy in machine learning. It covers topics such as:

- **Machine Unlearning**: Understanding the concept and importance of unlearning in the context of data privacy.
- **Private Training Models**: Techniques to ensure the privacy of models during training, including Differential Privacy and other privacy-preserving mechanisms.
- **Membership Inference Attacks**: Exploring how adversaries can infer if a specific data point was used in the training of a model and the implications for data privacy.

### Phase 1: Implementation
In this phase, we implemented the concepts studied in Phase 0. The implementation involves:

- **Machine Unlearning with the SISA Algorithm**: Implementing and evaluating the SISA (Sharded, Isolated, Sliced, and Aggregated) algorithm for efficient machine unlearning.
- **Private Model Training**: Training models with privacy enhancements and evaluating their robustness against Membership Inference Attacks.
- **Attack Simulations**: Conducting Membership Inference Attacks and Backdoor Attacks to test the privacy and security of our models.

## Files in this Repository

- `ML_project_phase0.pdf`: The detailed report for Phase 0, covering all theoretical discussions and proposed methods.
- `ML_phase1.ipynb`: The Jupyter notebook containing the code for implementing the machine unlearning and private training techniques.
- `Project_Phase1_Part2.ipynb`: Additional code and results for Phase 1, focusing on attack simulations and model evaluations.

## Authors
- **Nikoo Moradi**
- **Tina Halimi**
